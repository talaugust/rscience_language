{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency tests for posts \n",
    "This notebook is the analysis for identifying common and rare words within and outside of r/science (Table 2). \n",
    "This includes for first time and recurrent posters in r/science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import os \n",
    "os.chdir('/homes/gws/taugust/Projects/ARK/community_guidelines/')\n",
    "\n",
    "all_posts_dir = 'data/cleaned/real_subs_cleaned_posts_2018.csv'\n",
    "# science_related_posts_dir = 'data/cleaned/real_subs_cleaned_posts_2018_science_related.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a quick and simple tokenizer\n",
    "# (FWIW: I'm pretty sure I created this for something else, it's not perfect but ...\n",
    "# ... the point is to remove punctuation somewhat sensibly, lower case, and split)\n",
    "\n",
    "punct_chars = list(set(string.punctuation) - set(\"'\"))\n",
    "punct_chars.sort()\n",
    "punctuation = ''.join(punct_chars)\n",
    "replace = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def text_to_tokens(text, lower=True, ngram=None):\n",
    "    # replace underscores with spaces\n",
    "    text = re.sub(r'_', ' ', text)\n",
    "    # break off single quotes at the ends of words (e.g. 'test' -> test)\n",
    "    text = re.sub(r'\\s\\'', ' ', text)\n",
    "    text = re.sub(r'\\'\\s', ' ', text)\n",
    "    # remove periods (e.g. U.S. -> US)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    # replace all other punctuation (except single quotes) with spaces (e.g. T-rex -> t rex)\n",
    "    text = replace.sub(' ', text)\n",
    "    # remove single quotes (e.g. don't -> dont)\n",
    "    text = re.sub(r'\\'', '', text)\n",
    "    # replace all whitespace with a single space\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    # strip off spaces on either end\n",
    "    text = text.strip()    \n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    split_text = text.split()\n",
    "    if ngram is None:\n",
    "        return split_text\n",
    "    else:\n",
    "        return [tuple(split_text[i:i+ngram]) for i in range(len(split_text)-ngram+1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   created_utc   subreddit        author           domain  \\\n",
      "0   1532224574  askscience     mstilw577  self.askscience   \n",
      "1   1532224786  askscience  ballsosteele  self.askscience   \n",
      "2   1532224926  askscience       ntb2022  self.askscience   \n",
      "3   1532225571  askscience       tbqh123  self.askscience   \n",
      "4   1532229925  askscience    Ectricious  self.askscience   \n",
      "\n",
      "                                                 url  num_comments  score  \\\n",
      "0  https://www.reddit.com/r/askscience/comments/9...             5      2   \n",
      "1  https://www.reddit.com/r/askscience/comments/9...            13      3   \n",
      "2  https://www.reddit.com/r/askscience/comments/9...             3      4   \n",
      "3  https://www.reddit.com/r/askscience/comments/9...            10      2   \n",
      "4  https://www.reddit.com/r/askscience/comments/9...             6      1   \n",
      "\n",
      "   ups  downs                                              title  ...  \\\n",
      "0  NaN    NaN                 How do animals get stuck in amber?  ...   \n",
      "1  NaN    NaN  Why does it cost so much to send a man to the ...  ...   \n",
      "2  NaN    NaN         What happens chemcially when you fry food?  ...   \n",
      "3  NaN    NaN  What exactly does \"non-deterministic universe\"...  ...   \n",
      "4  NaN    NaN  If I were to pick a random location in the oce...  ...   \n",
      "\n",
      "                                           permalink name author_flair_text  \\\n",
      "0  /r/askscience/comments/90uga1/how_do_animals_g...  NaN               NaN   \n",
      "1  /r/askscience/comments/90uh06/why_does_it_cost...  NaN               NaN   \n",
      "2  /r/askscience/comments/90uhim/what_happens_che...  NaN               NaN   \n",
      "3  /r/askscience/comments/90ujv9/what_exactly_doe...  NaN               NaN   \n",
      "4  /r/askscience/comments/90uzhu/if_i_were_to_pic...  NaN               NaN   \n",
      "\n",
      "   quarantine  link_flair_text  distinguished  \\\n",
      "0       False          Biology            NaN   \n",
      "1       False        Astronomy            NaN   \n",
      "2       False        Chemistry            NaN   \n",
      "3       False          Physics            NaN   \n",
      "4       False   Earth Sciences            NaN   \n",
      "\n",
      "                                            fulltext  created_month  \\\n",
      "0  How do animals get stuck in amber?I was wonder...              7   \n",
      "1  Why does it cost so much to send a man to the ...              7   \n",
      "2  What happens chemcially when you fry food?And ...              7   \n",
      "3  What exactly does \"non-deterministic universe\"...              7   \n",
      "4  If I were to pick a random location in the oce...              7   \n",
      "\n",
      "                                               words word_count  \n",
      "0  ['How', 'do', 'animals', 'get', 'stuck', 'in',...         32  \n",
      "1  ['Why', 'does', 'it', 'cost', 'so', 'much', 't...        104  \n",
      "2  ['What', 'happens', 'chemcially', 'when', 'you...         19  \n",
      "3  ['What', 'exactly', 'does', '\"non-deterministi...         68  \n",
      "4  ['If', 'I', 'were', 'to', 'pick', 'a', 'random...         74  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "(115051, 37)\n"
     ]
    }
   ],
   "source": [
    "# read in all posts as a pandas object\n",
    "# infile = '../../../zinhome/dallas/reddit/all_posts_2018.csv'\n",
    "df = pd.read_csv(all_posts_dir, index_col=None, header=0, quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_dropped = df.drop(314793).drop(378189) # only two that are getting in the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115051\n"
     ]
    }
   ],
   "source": [
    "# convert to a list of json objects (THIS WILL TAKE A WHILE)\n",
    "outlines = []\n",
    "for i in df.index:\n",
    "    row = df.iloc[i]\n",
    "    outlines.append({'id': 'p' + str(i), 'subreddit': row['subreddit'], 'author': str(row['author']), 'title': str(row['title']), 'selftext': str(row['selftext']), 'month': int(row['created_month'])})\n",
    "\n",
    "print(len(outlines)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each instance (THIS WILL ALSO TAKE A WHILE)\n",
    "for line in outlines:\n",
    "    line['title_tokens'] = text_to_tokens(line['title'], ngram=1)\n",
    "    line['selftext_tokens'] = text_to_tokens(line['selftext'], ngram=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'p0', 'subreddit': 'askscience', 'author': 'mstilw577', 'title': 'How do animals get stuck in amber?', 'selftext': 'I was wondering how animals and insects get stuck in amber. Did the animals fall into the amber before it solidified? Or does it happen differently?', 'month': 7, 'title_tokens': [('how',), ('do',), ('animals',), ('get',), ('stuck',), ('in',), ('amber',)], 'selftext_tokens': [('i',), ('was',), ('wondering',), ('how',), ('animals',), ('and',), ('insects',), ('get',), ('stuck',), ('in',), ('amber',), ('did',), ('the',), ('animals',), ('fall',), ('into',), ('the',), ('amber',), ('before',), ('it',), ('solidified',), ('or',), ('does',), ('it',), ('happen',), ('differently',)]}\n"
     ]
    }
   ],
   "source": [
    "print(outlines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the list of jsob objects to a file (just in case you want to re-start this analysis later)\n",
    "with open('data/cleaned/all_posts_2018.jsonlist', 'w') as f:\n",
    "    for line in outlines:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it back in (START HERE if you have already done the above and are re-starting this notebook)\n",
    "with open('data/cleaned/all_posts_2018.jsonlist') as f:\n",
    "    posts = f.readlines()\n",
    "posts = [json.loads(line) for line in posts]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AskHistorians', 41203), ('science', 22157), ('Futurology', 20127), ('askscience', 12162), ('dataisbeautiful', 8437), ('EverythingScience', 6772), ('TrueReddit', 4193)]\n"
     ]
    }
   ],
   "source": [
    "# count the number of posts in each subreddit\n",
    "subreddit_counter = Counter()\n",
    "subreddit_counter.update([line['subreddit'] for line in posts])\n",
    "print(subreddit_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6772\n",
      "108279\n"
     ]
    }
   ],
   "source": [
    "# split into science and non-science\n",
    "# making this instead askscience\n",
    "science = [line for line in posts if line['subreddit'] == 'science']\n",
    "print(len(science))\n",
    "background = [line for line in posts if line['subreddit'] != 'science']\n",
    "print(len(background))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "word = 'bàn'\n",
    "for post in science:\n",
    "    if word in post['title_tokens'] or word in post['selftext_tokens']:\n",
    "        print(post)\n",
    "        count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list for bigrams to tuple\n",
    "def convert_to_tuple(line, cols):\n",
    "    for col in cols:\n",
    "        line[col] = [tuple(bigram) for bigram in line[col]]\n",
    "    return line\n",
    "\n",
    "science = list(map(lambda line: convert_to_tuple(line, ['selftext_tokens', 'title_tokens']), science))\n",
    "background = list(map(lambda line: convert_to_tuple(line, ['selftext_tokens', 'title_tokens']), background))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16274 112285\n",
      "114320\n",
      "122653 5127351\n"
     ]
    }
   ],
   "source": [
    "# count the tokens in science and background\n",
    "science_counts = Counter()\n",
    "bg_counts = Counter()\n",
    "\n",
    "# *** modify these to choose whether to use title and/or body ***\n",
    "use_title = True\n",
    "use_selftext = True\n",
    "\n",
    "for line in science:\n",
    "    if use_title:\n",
    "        science_counts.update(line['title_tokens'])\n",
    "    if use_selftext:\n",
    "        science_counts.update(line['selftext_tokens'])\n",
    "for line in background:\n",
    "    if use_title:\n",
    "        bg_counts.update(line['title_tokens'])    \n",
    "    if use_selftext:\n",
    "        bg_counts.update(line['selftext_tokens'])    \n",
    "print(len(science_counts), len(bg_counts))\n",
    "\n",
    "# make a common vocabulary\n",
    "common = set()\n",
    "common.update(science_counts.keys())\n",
    "common.update(bg_counts.keys())\n",
    "common = list(common)\n",
    "common.sort()\n",
    "print(len(common))\n",
    "\n",
    "# get the the total number of tokens in each\n",
    "science_N = sum(science_counts.values())\n",
    "bg_N = sum(bg_counts.values())\n",
    "print(science_N, bg_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert counts to arrays of size equal to the vocabulary (common)\n",
    "science_counts_array = np.array([science_counts[w] if w in science_counts else 0 for w in common])\n",
    "bg_counts_array = np.array([bg_counts[w] if w in bg_counts else 0 for w in common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=14473359.836986423, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# do a Chi-squared test on the difference in counts (just for fun)\n",
    "from scipy import stats\n",
    "print(stats.chisquare(science_counts_array, bg_counts_array+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsmoothing = 0.1\\nbg_counts_array = bg_counts_array + smoothing\\nbg_counts_N_temp = bg_counts_array.sum()\\npvals = []\\ntestvals = []\\nfor i in range(len(common)):\\n    chisq, p = stats.chisquare([science_counts_array[i], science_N - science_counts_array[i]], \\n                              [bg_counts_array[i], bg_counts_N_temp - bg_counts_array[i]])\\n    pvals.append(p)\\n    testvals.append(chisq)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "smoothing = 0.1\n",
    "bg_counts_array = bg_counts_array + smoothing\n",
    "bg_counts_N_temp = bg_counts_array.sum()\n",
    "pvals = []\n",
    "testvals = []\n",
    "for i in range(len(common)):\n",
    "    chisq, p = stats.chisquare([science_counts_array[i], science_N - science_counts_array[i]], \n",
    "                              [bg_counts_array[i], bg_counts_N_temp - bg_counts_array[i]])\n",
    "    pvals.append(p)\n",
    "    testvals.append(chisq)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114320\n"
     ]
    }
   ],
   "source": [
    "# compute the probability of each word count in science, using probabilities estimated from the background\n",
    "smoothing = 0.1\n",
    "probs = []\n",
    "pvals = []\n",
    "vocab_size = len(common)\n",
    "for word in common:\n",
    "    # convert counts in the background into (smoothed) probabilities\n",
    "    if word in bg_counts:\n",
    "        bg_c = bg_counts[word] + smoothing\n",
    "        bg_p = (bg_counts[word] + smoothing) / float(bg_N + smoothing * len(common))\n",
    "    else:\n",
    "        bg_c = smoothing\n",
    "        bg_p = (smoothing) / float(bg_N + smoothing * len(common))\n",
    "    # get the word counts in science\n",
    "    if word in science_counts:\n",
    "        count = science_counts[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    # for each word, compute the probability of the observed count, given the background frequency\n",
    "    prob = stats.binom.logpmf(k=count, n=science_N, p=bg_p)\n",
    "    # also do a chi-squared test\n",
    "    chisq, pval = stats.chisquare([count, science_N - count], \n",
    "                              [bg_c, bg_N + smoothing * vocab_size - bg_c])\n",
    "    # save the pvals and probabilities\n",
    "    pvals.append(pval * vocab_size)    \n",
    "    probs.append(prob)\n",
    "    \n",
    "print(len(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  word  probability  pval  science_freq       bg_freq\n",
      "2        (scientists,)  -657.339602   0.0      0.004378  5.419953e-04\n",
      "4               (new,)  -573.230322   0.0      0.007786  2.066369e-03\n",
      "6             (study,)  -528.386195   0.0      0.005088  9.835488e-04\n",
      "7           (climate,)  -484.762156   0.0      0.003123  3.695866e-04\n",
      "8    (scienceseekers,)  -480.348014   0.0      0.000432  0.000000e+00\n",
      "9      (sciseekpicks,)  -480.348014   0.0      0.000432  0.000000e+00\n",
      "10          (scicomm,)  -353.283422   0.0      0.000432  1.950325e-07\n",
      "12              (may,)  -292.919288   0.0      0.003335  7.627720e-04\n",
      "14              (epa,)  -284.311455   0.0      0.000652  7.216202e-06\n",
      "15         (research,)  -255.464852   0.0      0.002976  6.960709e-04\n",
      "16      (researchers,)  -252.705769   0.0      0.002479  4.914819e-04\n",
      "17                (–,)  -252.345643   0.0      0.001786  2.422303e-04\n",
      "19                (и,)  -236.323031   0.0      0.000440  2.145357e-06\n",
      "20           (cancer,)  -232.256304   0.0      0.001940  3.235589e-04\n",
      "24            (trump,)  -217.504728   0.0      0.001239  1.234556e-04\n",
      "26            (picks,)  -201.655463   0.0      0.000457  4.875812e-06\n",
      "28          (newscom,)  -198.065121   0.0      0.000261  1.950325e-07\n",
      "30            (shows,)  -188.257971   0.0      0.001696  3.087364e-04\n",
      "32            (brain,)  -180.999529   0.0      0.001981  4.396032e-04\n",
      "36       (scientific,)  -162.431144   0.0      0.001052  1.275512e-04\n",
      "38          (reveals,)  -145.581498   0.0      0.000823  8.191364e-05\n",
      "41           (change,)  -136.392189   0.0      0.002201  6.744223e-04\n",
      "42           (health,)  -136.134939   0.0      0.001296  2.519820e-04\n",
      "43            (finds,)  -131.981064   0.0      0.001239  2.375496e-04\n",
      "44             (nasa,)  -131.878340   0.0      0.000872  1.096083e-04\n",
      "46            (hakai,)  -127.279984   0.0      0.000130  0.000000e+00\n",
      "47                (в,)  -124.331422   0.0      0.000261  2.145357e-06\n",
      "48                (—,)  -118.684513   0.0      0.001084  2.024437e-04\n",
      "50           (pruitt,)  -112.658001   0.0      0.000220  1.365227e-06\n",
      "56        (scientist,)   -94.509935   0.0      0.000603  7.294215e-05\n",
      "57             (drug,)   -89.202131   0.0      0.000856  1.696783e-04\n",
      "59             (week,)   -88.805087   0.0      0.000742  1.265761e-04\n",
      "61             (gene,)   -86.762957   0.0      0.000766  1.392532e-04\n",
      "63          (disease,)   -84.659222   0.0      0.001019  2.506167e-04\n",
      "64        (chembites,)   -83.920915   0.0      0.000090  0.000000e+00\n",
      "65         (crumbles,)   -83.339257   0.0      0.000147  5.850975e-07\n",
      "66          (vaccine,)   -82.335859   0.0      0.000505  5.811968e-05\n",
      "67            (human,)   -81.487137   0.0      0.001843  7.056275e-04\n",
      "68              (dna,)   -80.464238   0.0      0.000889  2.026388e-04\n",
      "73            (posts,)   -74.233683   0.0      0.000497  6.494582e-05\n",
      "75            (earth,)   -73.575368   0.0      0.001272  4.140540e-04\n",
      "76         (suggests,)   -71.603028   0.0      0.000783  1.774796e-04\n",
      "77             (risk,)   -71.184040   0.0      0.000946  2.539323e-04\n",
      "78       (discovered,)   -71.058103   0.0      0.000815  1.932772e-04\n",
      "79           (reveal,)   -68.178616   0.0      0.000416  4.778296e-05\n",
      "80             (nber,)   -67.144684   0.0      0.000073  0.000000e+00\n",
      "81  (археологические,)   -67.144684   0.0      0.000073  0.000000e+00\n",
      "82            (alien,)   -66.749552   0.0      0.000351  3.198533e-05\n",
      "84          (warming,)   -65.300409   0.0      0.000497  7.703783e-05\n",
      "85           (report,)   -65.253564   0.0      0.000693  1.534906e-04\n",
      "86             (blog,)   -64.955400   0.0      0.000310  2.398900e-05\n",
      "87       (mysterious,)   -64.671817   0.0      0.000310  2.418403e-05\n",
      "88           (global,)   -63.591216   0.0      0.000897  2.533472e-04\n",
      "90        (treatment,)   -62.472925   0.0      0.000717  1.710435e-04\n",
      "91          (physics,)   -61.766522   0.0      0.000628  1.335973e-04\n",
      "92               (из,)   -61.515492   0.0      0.000106  3.900650e-07\n",
      "94             (test,)   -61.081472   0.0      0.000669  1.527104e-04\n",
      "95              (fda,)   -60.869316   0.0      0.000334  3.296049e-05\n",
      "96              (lab,)   -60.865759   0.0      0.000530  9.615101e-05\n",
      "98           (review,)   -60.159681   0.0      0.000465  7.352725e-05\n"
     ]
    }
   ],
   "source": [
    "# sort by the probabilities computed above and display the top terms\n",
    "order = list(np.argsort(probs))\n",
    "df = pd.DataFrame(columns=['word', 'probability', 'pval', 'science_freq', 'bg_freq'])\n",
    "for i in range(1, 50000):\n",
    "    # print those words that have *higher* probability in science than background\n",
    "    word = common[order[i]]\n",
    "    if word in science_counts:\n",
    "        sc_count = science_counts[word]\n",
    "    else:\n",
    "        sc_count = 0\n",
    "    if word in bg_counts:\n",
    "        bg_count = bg_counts[word]\n",
    "    else:\n",
    "        bg_count = 0\n",
    "    if sc_count / science_N > bg_count / bg_N:\n",
    "        df.loc[i] = [word, probs[order[i]], pvals[order[i]], sc_count / science_N, bg_count / bg_N]\n",
    "# actually, sort on multiple values because of round-off error in pvals\n",
    "df = df.sort_values(['probability', 'science_freq'],  ascending=[True, False])\n",
    "df.to_csv('common_in_science_posts.csv')\n",
    "print(df.head(n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word  probability  pval  science_freq   bg_freq\n",
      "1             (i,)  -882.999538   0.0      0.000848  0.010099\n",
      "3           (was,)  -593.647384   0.0      0.001337  0.008632\n",
      "5           (did,)  -553.670344   0.0      0.000351  0.005824\n",
      "11           (or,)  -302.223886   0.0      0.001794  0.006551\n",
      "13         (were,)  -291.752873   0.0      0.000946  0.004843\n",
      "18          (any,)  -241.750982   0.0      0.000334  0.003021\n",
      "21        (there,)  -228.659420   0.0      0.000905  0.004115\n",
      "22          (the,)  -221.871074   0.0      0.040341  0.053252\n",
      "23        (would,)  -220.772163   0.0      0.000823  0.003875\n",
      "25         (what,)  -207.980370   0.0      0.002389  0.006414\n",
      "27           (it,)  -199.940396   0.0      0.004183  0.008970\n",
      "29           (im,)  -195.104376   0.0      0.000065  0.001861\n",
      "31           (if,)  -181.457598   0.0      0.001150  0.004052\n",
      "33         (this,)  -173.268451   0.0      0.002788  0.006554\n",
      "34         (they,)  -172.093404   0.0      0.001622  0.004737\n",
      "35           (my,)  -168.110242   0.0      0.000375  0.002425\n",
      "37          (war,)  -148.673994   0.0      0.000261  0.001983\n",
      "39           (so,)  -141.835741   0.0      0.001076  0.003467\n",
      "40          (but,)  -140.857545   0.0      0.001737  0.004519\n",
      "45        (https,)  -129.156711   0.0      0.000057  0.001274\n",
      "49           (oc,)  -113.646725   0.0      0.000008  0.000967\n",
      "51         (that,)  -108.333983   0.0      0.007639  0.011826\n",
      "52           (me,)  -105.011444   0.0      0.000188  0.001403\n",
      "53          (ive,)  -103.514577   0.0      0.000024  0.000947\n",
      "54         (know,)  -100.828792   0.0      0.000595  0.002162\n",
      "55         (like,)   -97.886366   0.0      0.001166  0.003066\n",
      "58          (how,)   -89.116816   0.0      0.004183  0.007080\n",
      "60           (am,)   -87.721301   0.0      0.000073  0.000962\n",
      "62     (question,)   -85.841076   0.0      0.000139  0.001109\n",
      "69       (empire,)   -79.982709   0.0      0.000016  0.000721\n",
      "70        (roman,)   -78.746786   0.0      0.000041  0.000791\n",
      "71        (seems,)   -76.288852   0.0      0.000057  0.000817\n",
      "72           (he,)   -75.581336   0.0      0.000473  0.001661\n",
      "74          (and,)   -73.791736   0.0      0.017529  0.022350\n",
      "83          (had,)   -66.208174   0.0      0.000514  0.001621\n",
      "89        (other,)   -63.355430   0.0      0.000897  0.002189\n",
      "93       (during,)   -61.430348   0.0      0.000571  0.001657\n",
      "97           (do,)   -60.376217   0.0      0.001207  0.002599\n",
      "99    (wondering,)   -59.734923   0.0      0.000000  0.000488\n",
      "100        (such,)   -59.680826   0.0      0.000277  0.001134\n",
      "102         (etc,)   -59.058659   0.0      0.000049  0.000643\n",
      "110     (history,)   -56.351275   0.0      0.000546  0.001554\n",
      "115          (as,)   -55.333812   0.0      0.003938  0.006050\n",
      "126        (then,)   -51.740032   0.0      0.000147  0.000799\n",
      "139    (military,)   -48.734711   0.0      0.000024  0.000483\n",
      "146      (german,)   -47.164535   0.0      0.000041  0.000515\n",
      "148       (where,)   -47.086206   0.0      0.000465  0.001307\n",
      "149    (medieval,)   -47.017480   0.0      0.000016  0.000444\n",
      "157   (something,)   -44.806190   0.0      0.000171  0.000777\n",
      "160        (much,)   -44.459897   0.0      0.000546  0.001400\n",
      "166        (also,)   -43.054140   0.0      0.000497  0.001306\n",
      "167       (about,)   -42.957030   0.0      0.002430  0.003903\n",
      "173     (reading,)   -42.620091   0.0      0.000082  0.000572\n",
      "178         (ww2,)   -41.205653   0.0      0.000000  0.000337\n",
      "185     (germany,)   -40.067472   0.0      0.000065  0.000511\n",
      "186  (historians,)   -39.940225   0.0      0.000000  0.000326\n",
      "187  (historical,)   -39.538963   0.0      0.000041  0.000447\n",
      "188      (thanks,)   -39.441045   0.0      0.000098  0.000576\n",
      "190     (example,)   -39.111283   0.0      0.000073  0.000520\n",
      "192        (some,)   -38.265166   0.0      0.001125  0.002129\n"
     ]
    }
   ],
   "source": [
    "# do the same thing, but for those words that have  *lower* probability in science than background\n",
    "order = list(np.argsort(probs))\n",
    "df = pd.DataFrame(columns=['word', 'probability', 'pval', 'science_freq', 'bg_freq'])\n",
    "for i in range(50000):\n",
    "    word = common[order[i]]\n",
    "    if word in science_counts:\n",
    "        sc_count = science_counts[word]\n",
    "    else:\n",
    "        sc_count = 0\n",
    "    if word in bg_counts:\n",
    "        bg_count = bg_counts[word]\n",
    "    else:\n",
    "        bg_count = 0\n",
    "    if sc_count / science_N < bg_count / bg_N:\n",
    "        df.loc[i] = [word, probs[order[i]], pvals[order[i]], sc_count / science_N, bg_count / bg_N]\n",
    "df = df.sort_values(['probability', 'science_freq'],  ascending=[True, False])\n",
    "df.to_csv('rare_in_science.csv')\n",
    "print(df.head(n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0, 948, 159,  73,  36,  26,  28,  18,   9,  16,   8,   4,   4,\n",
       "          8,   6,   8,   8,   1,   4]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count post authors\n",
    "post_authors = Counter()\n",
    "post_authors.update([line['author'] for line in science])\n",
    "np.histogram([v for v in post_authors.values()], bins = np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948\n",
      "5143\n"
     ]
    }
   ],
   "source": [
    "# count rare vs common posters\n",
    "new_posters = [line for line in science if post_authors[line['author']] == 1]\n",
    "regular_posters = [line for line in science if post_authors[line['author']] >= 5]\n",
    "print(len(new_posters))\n",
    "print(len(regular_posters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4977 14040\n",
      "15433\n",
      "16086 95132\n"
     ]
    }
   ],
   "source": [
    "# do the same sort of comparison comparing rare vs frequent posters\n",
    "newuser_counts = Counter()\n",
    "regular_counts = Counter()\n",
    "use_title = True\n",
    "use_selftext = True\n",
    "for line in new_posters:\n",
    "    # added check that title doesn't have ama (jama is a journal)\n",
    "#     if (any(ama_str in line['title'] for ama_str in ['AMA', 'this ama'])) and (not 'JAMA' in line['title']):\n",
    "#         continue\n",
    "    if use_title:\n",
    "        newuser_counts.update(line['title_tokens'])\n",
    "    if use_selftext:\n",
    "        newuser_counts.update(line['selftext_tokens'])\n",
    "for line in regular_posters:\n",
    "    if use_title:\n",
    "        regular_counts.update(line['title_tokens'])    \n",
    "    if use_selftext:\n",
    "        regular_counts.update(line['selftext_tokens'])    \n",
    "print(len(newuser_counts), len(regular_counts))\n",
    "common = set()\n",
    "common.update(newuser_counts.keys())\n",
    "common.update(regular_counts.keys())\n",
    "common = list(common)\n",
    "common.sort()\n",
    "print(len(common))\n",
    "new_N = sum(newuser_counts.values())\n",
    "reg_N = sum(regular_counts.values())\n",
    "print(new_N, reg_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15433\n"
     ]
    }
   ],
   "source": [
    "smoothing = 0.1\n",
    "probs = []\n",
    "pvals = []\n",
    "vocab_size = len(common)\n",
    "for word in common:\n",
    "    if word in regular_counts:\n",
    "        bg_c = regular_counts[word] + smoothing\n",
    "        bg_p = (regular_counts[word] + smoothing) / float(reg_N + smoothing * len(common))\n",
    "    else:\n",
    "        bg_c = smoothing\n",
    "        bg_p = (smoothing) / float(reg_N + smoothing * len(common))\n",
    "    if word in newuser_counts:\n",
    "        count = newuser_counts[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob = stats.binom.logpmf(k=count, n=new_N, p=bg_p)\n",
    "    chisq, pval = stats.chisquare([count, new_N - count], \n",
    "                              [bg_c, reg_N + smoothing * vocab_size - bg_c])\n",
    "    pvals.append(pval * vocab_size)    \n",
    "    probs.append(prob)\n",
    "    \n",
    "print(len(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-53916932c55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'science_freq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bg_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewuser_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msc_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewuser_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "order = list(np.argsort(probs))\n",
    "df = pd.DataFrame(columns=['word', 'probability', 'pval', 'science_freq', 'bg_freq'])\n",
    "for i in range(1, 20000):\n",
    "    word = common[order[i]]\n",
    "    if word in newuser_counts:\n",
    "        sc_count = newuser_counts[word]\n",
    "    else:\n",
    "        sc_count = 0\n",
    "    if word in regular_counts:\n",
    "        bg_count = regular_counts[word]\n",
    "    else:\n",
    "        bg_count = 0\n",
    "    if sc_count / new_N > bg_count / reg_N:\n",
    "        df.loc[i] = [word, probs[order[i]], pvals[order[i]], sc_count / new_N, bg_count / reg_N]\n",
    "df = df.sort_values(['probability', 'science_freq'],  ascending=[True, False])\n",
    "df.to_csv('common_in_science_posts_newusers.csv')\n",
    "print(df.head(n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = list(np.argsort(probs))\n",
    "df = pd.DataFrame(columns=['word', 'probability', 'pval', 'science_freq', 'bg_freq'])\n",
    "for i in range(1, 20000):\n",
    "    word = common[order[i]]\n",
    "    if word in newuser_counts:\n",
    "        sc_count = newuser_counts[word]\n",
    "    else:\n",
    "        sc_count = 0\n",
    "    if word in regular_counts:\n",
    "        bg_count = regular_counts[word]\n",
    "    else:\n",
    "        bg_count = 0\n",
    "    if sc_count / new_N < bg_count / reg_N:\n",
    "        df.loc[i] = [word, probs[order[i]], pvals[order[i]], sc_count / new_N, bg_count / reg_N]\n",
    "df = df.sort_values(['probability', 'science_freq'],  ascending=[True, False])\n",
    "df.to_csv('rare_in_science_posts_newusers.csv')\n",
    "print(df.head(n=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "word = 'bàn'\n",
    "for post in science:\n",
    "    if word in post['title_tokens'] or word in post['selftext_tokens']:\n",
    "        print(post)\n",
    "        count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
