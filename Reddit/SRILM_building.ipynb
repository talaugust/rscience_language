{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building SRILM LMs \n",
    "This should be the only place that you actually need to train these SLMs, since SRILM will save them and you can load them using the 'use_saved_lms=True' param in build_monthly_SLM_SRILM()\n",
    "Using these resources for SRILM: https://okapiframework.org/wiki/index.php?title=SRILM_Installation_and_Running_Tutorial, http://www.cs.brandeis.edu/~cs114/CS114_docs/SRILM_Tutorial_20080512.pdf, \n",
    "http://www.speech.sri.com/projects/srilm/manpages/ngram-count.1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/gws/taugust/Projects/ARK/community_guidelines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/homes/gws/taugust/Projects/ARK/community_guidelines')\n",
    "\n",
    "%run Reddit/SRILM_building_funcs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Science building LMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  \u001b[35mdata/cleaned/sub_comments/science_comments_2018.csv\u001b[0m ..... Done\n",
      "Importing  \u001b[35mdata/cleaned/train/2018/author_counts/science_author_counts_train_2018.csv\u001b[0m ..... Done\n",
      "Importing  \u001b[35mdata/cleaned/sub_posts/science_posts_2018.csv\u001b[0m ..... Done\n",
      "Importing  \u001b[35mdata/cleaned/train/2018/author_counts/science_author_counts_train_2018.csv\u001b[0m ..... Done\n"
     ]
    }
   ],
   "source": [
    "s = 'science'\n",
    "\n",
    "df_comments, df_author_counts_train = import_csvs(s, path='data/cleaned/train/2018/', ext='_train_2018.csv', comment_pre_path='data/cleaned/sub_comments/', comment_ext='_comments_2018.csv')\n",
    "df_posts, df_author_counts_train = import_csvs(s, path='data/cleaned/train/2018/', ext='_train_2018.csv', comment_pre_path='data/cleaned/sub_posts/', comment_ext='_posts_2018.csv')\n",
    "\n",
    "df_posts = df_posts.rename(index=str, columns={'fulltext': 'body'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'colored' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01bb22b02319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# for i, s in enumerate(subs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building SLMs for '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'magenta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'colored' is not defined"
     ]
    }
   ],
   "source": [
    "# real subs CHANGED DIRECTORY OF LMS\n",
    "# subs = ['Cooking', 'mentalhealth', 'Seahawks', 'science', 'politics','news', 'BabyBumps']\n",
    "\n",
    "\n",
    "# for i, s in enumerate(subs):\n",
    "print('-----------------------------------------------')\n",
    "print('Building SLMs for ', colored(s, 'magenta'))\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "    \n",
    "# buidling full LMs\n",
    "build_monthly_SLM_SRILM(df_comments, df_author_counts_train, slm_count=100, name=s, use_saved_lms=False, kind='comment', num_authors=200, threshold_count=5, year='2018', full=True)\n",
    "build_total_SLM_SRILM(df_posts, df_author_counts_train, slm_count=100, name=s, use_saved_lms=False, kind='post', num_authors=200, threshold_count=5, year='2018', full=True)\n",
    "\n",
    "# Building LMs with just the begining of each sentence\n",
    "build_monthly_SLM_SRILM(df_comments, df_author_counts_train, slm_count=100, name=s, use_saved_lms=False, kind='comment', num_authors=200, threshold_count=5, year='2018', full=False)\n",
    "build_total_SLM_SRILM(df_posts, df_author_counts_train, slm_count=100, name=s, use_saved_lms=False, kind='post', num_authors=200, threshold_count=5, year='2018', full=False) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  \u001b[35mdata/cleaned/sub_comments/science_comments_2018.csv\u001b[0m ..... Done\n",
      "Importing  \u001b[35mdata/cleaned/train/2018/author_counts/science_author_counts_train_2018.csv\u001b[0m ..... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/taugust/miniconda3/envs/reddit/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/homes/gws/taugust/miniconda3/envs/reddit/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07395957193816885\n",
      "0.052984394272537136\n",
      "0.06566675756749386\n",
      "0.06090133982947625\n",
      "0.06094129684102827\n",
      "0.06333947853568607\n",
      "0.06910401039513318\n",
      "0.06890443313953488\n",
      "0.06680972818311874\n",
      "0.05974630798455788\n",
      "0.06353577575608557\n",
      "0.06369426751592357\n",
      "0.06509073543457497\n"
     ]
    }
   ],
   "source": [
    "# good proof for using 5 authors as my limit\n",
    "df_comments, df_author_counts_train = import_csvs('science', path='data/cleaned/train/2018/', ext='_train_2018.csv', comment_pre_path='data/cleaned/sub_comments/', comment_ext='_comments_2018.csv')\n",
    "\n",
    "df_author_post = df_author_counts_train[df_author_counts_train['kind'] == 'post']\n",
    "df_author_comment = df_author_counts_train[df_author_counts_train['kind'] == 'comment']\n",
    "df_author_post['total'] = df_author_post[[str(m) for m in range(1,13)]].sum(axis=1)\n",
    "df_author_comment['total'] = df_author_comment[[str(m) for m in range(1,13)]].sum(axis=1)\n",
    "\n",
    "print(sum(df_author_post['total'] >= 5)/len(df_author_post['total']))\n",
    "for i in range(1, 13):\n",
    "    print(sum(df_author_comment[str(i)] >= 5)/sum(df_author_comment[str(i)] > 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "reddit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
